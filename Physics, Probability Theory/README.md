# (Mathematical) Physics, Probability Theory

This folder is divided into several subfolders and papers that are just too broad to be classified into subcategories. The main theme of this folder is to understand deep learning by using concepts and techniques/tools from (mathematical) physics and probability theory. These include, but are not limited to, random matrix theory (RMT), mean-field theory (MFT), spin glass...etc.



## The Loss Surfaces of Multilayer Networks (Choromanska et al., AISTATS'15)

- 

## Traditional and Heavy Tailed Self Regularization in Neural Network Models (Martin & Mahoney, ICML'19)

- Extended version *Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning* by Martin&Mahoney available on arXiv.

## Nonlinear random matrix theory for deep learning (Pennington & Worah, 2019; *Journal of Statistical Mechanics: Theory and Experiment*)

- Preliminary version of the same title appeared in NIPS'19
- 



